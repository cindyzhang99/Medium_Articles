{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Save_weights_before_after_training.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO1bHvzqMBIP3RWzzAAb7FQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jvishnuvardhan/Medium_Articles/blob/master/Save_weights_before_after_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsuesJ6E7s2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "0e359a96-b802-447c-edb2-69b0484cd007"
      },
      "source": [
        "!pip install tensorflow==2.2"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.2 in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (0.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (3.2.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.29.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.1.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (2.2.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (2.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (0.3.3)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.6.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (2.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.18.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.12.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.2) (47.3.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.17.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.6.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2020.4.5.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.0.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZHJPDkz7u9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import modules\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os, datetime\n",
        "import numpy as np\n",
        "\n",
        "Epochs = 10\n",
        "# Load data\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# Split the data to train and test\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Process the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Define model\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28), name='Flatten'),\n",
        "    tf.keras.layers.Dense(512, activation='relu', name = 'Dense1'),\n",
        "    tf.keras.layers.Dropout(0.2, name = 'Dropout'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', name = 'Output')\n",
        "    ])\n",
        "  \n",
        "  return model\n",
        "\n",
        "# Create a basic model instance\n",
        "model = create_model()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy', \n",
        "            metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJu8vUK0759T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cc720948-1a85-4130-acb1-46d55ac1cfd3"
      },
      "source": [
        "# Saving weights before training (tf format)\n",
        "model.save_weights('My_weights_tf',save_format='tf')\n",
        "\n",
        "# Saving weights before training (h5 format)\n",
        "model.save_weights('My_weights_h5',save_format='h5')\n",
        "\n",
        "#prediction\n",
        "prediction_model = model.predict(tf.reshape(x_test[0],shape=(1,28,28)))\n",
        "print(\"Prediction with original model : \", np.argmax(prediction_model))\n",
        "# Instantiate new model\n",
        "new_model = create_model() # Initializes new random weights and biases\n",
        "#print(new_model.weights)\n",
        "\n",
        "#print('original model')\n",
        "#print(model.weights) # notice that original model weights and new_model weights are different\n",
        "\n",
        "#prediction\n",
        "prediction_new_model = new_model.predict(tf.reshape(x_test[0],shape=(1,28,28)))\n",
        "print(\"Prediction with new model : \", np.argmax(prediction_new_model))\n",
        "\n",
        "# prediction after loading saved weights\n",
        "new_model.load_weights('My_weights_tf')\n",
        "prediction_new_model_after_loading_weights = new_model.predict(tf.reshape(x_test[0],shape=(1,28,28)))\n",
        "print(\"Prediction with new model (after loading weights) : \", np.argmax(prediction_new_model_after_loading_weights))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction with original model :  0\n",
            "Prediction with new model :  9\n",
            "Prediction with new model (after loading weights) :  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erlz7IGm75Mr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f1641bb1-8f10-4f8f-bafa-37f545339d86"
      },
      "source": [
        "# train the modell\n",
        "model.fit(x_train, y_train, epochs = 1, validation_data=(x_test, y_test), verbose=1)\n",
        "\n",
        "# Saving weights after training (tf format)\n",
        "model.save_weights('My_weights_tf_after_training',save_format='tf')\n",
        "\n",
        "# Saving weights after training (h5 format)\n",
        "model.save_weights('My_weights_h5_after_training',save_format='h5')\n",
        "\n",
        "# evaluate loss and accuracy\n",
        "loss, acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(\"Original model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2167 - accuracy: 0.9358 - val_loss: 0.1121 - val_accuracy: 0.9644\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1121 - accuracy: 0.9644\n",
            "Original model, accuracy: 96.44%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXtCmmS6LfSn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8c617d66-36eb-4fdd-f985-d6546507e94f"
      },
      "source": [
        "# Instantiate new model\n",
        "new_model = create_model() # Initializes new random weights and biases\n",
        "\n",
        "# Compile the model (new_model)\n",
        "new_model.compile(optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy', \n",
        "            metrics=['accuracy'])\n",
        "\n",
        "# prediction after loading saved weights (after training)\n",
        "new_model.load_weights('My_weights_tf_after_training')\n",
        "\n",
        "# evaluate loss and accuracy\n",
        "loss, acc_afte_loading_weights = new_model.evaluate(x_test, y_test, verbose=1)\n",
        "print(\"new_model, accuracy: {:5.2f}%\".format(100*acc_afte_loading_weights))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1121 - accuracy: 0.9644\n",
            "new_model, accuracy: 96.44%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMDOQIKQMJvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "552a7bf9-2ccc-45a7-d3e6-a331c5d5db28"
      },
      "source": [
        "# When the model has a custom metric with external params\n",
        "\n",
        "# Instantiate new model\n",
        "model2 = create_model() # Initializes new random weights and biases\n",
        "\n",
        "magic_num = 1 # This is just for demonstrating usage of an external parameter inside custom metric\n",
        "\n",
        "# Custom Metric (with external parameters)\n",
        "def metric_with_params(magic_num):\n",
        "  def metric(yTrue,yPred):\n",
        "    yTrue = yTrue*magic_num\n",
        "    return tf.keras.metrics.sparse_categorical_accuracy(yTrue, yPred)\n",
        "  return metric\n",
        "\n",
        "# Compile the model\n",
        "model2.compile(optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy', metric_with_params(magic_num)])\n",
        "\n",
        "# train the modell\n",
        "model2.fit(x_train, y_train, epochs = 1, validation_data=(x_test, y_test), verbose=1)\n",
        "\n",
        "# Saving weights after training (tf format)\n",
        "model2.save_weights('My_weights_custom_metric',save_format='tf')\n",
        "# evaluate loss and accuracy\n",
        "loss, acc,acc_cust = model2.evaluate(x_test, y_test, verbose=1)\n",
        "print(\"Original model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2184 - accuracy: 0.9350 - metric: 0.9350 - val_loss: 0.1045 - val_accuracy: 0.9687 - val_metric: 0.9687\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1045 - accuracy: 0.9687 - metric: 0.9687\n",
            "Original model, accuracy: 96.87%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBx9spRdcGpw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ef8beff7-f9d2-40c1-acb4-b02563aa5edc"
      },
      "source": [
        "# Instantiate new model\n",
        "model_loaded = create_model() # Initializes new random weights and biases\n",
        "\n",
        "# Compile the model (new_model)\n",
        "model_loaded.compile(optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy', \n",
        "            metrics=['accuracy',metric_with_params(magic_num)])\n",
        "\n",
        "# prediction after loading saved weights (after training)\n",
        "model_loaded.load_weights('My_weights_custom_metric')\n",
        "\n",
        "# evaluate loss and accuracy\n",
        "loss, acc_after_loading,acc_cust = model_loaded.evaluate(x_test, y_test, verbose=1)\n",
        "print(\"new_model, accuracy: {:5.2f}%\".format(100*acc_after_loading))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1045 - accuracy: 0.9687 - metric: 0.9687\n",
            "new_model, accuracy: 96.87%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}